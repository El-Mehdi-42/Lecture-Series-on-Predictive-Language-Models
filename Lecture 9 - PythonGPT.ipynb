{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages and installing openai"
      ],
      "metadata": {
        "id": "hRX5jVvVrvSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "N9ShHxhbb-IU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt3b4Zz1V5-M",
        "outputId": "6c7168a9-3bcc-445d-9eb5-f83086efb10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You should change ```\"your-key\"``` with your key from <a>https://platform.openai.com/api-keys</a>"
      ],
      "metadata": {
        "id": "G-IJb4War0k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = \"your-key\"\n",
        "\n",
        "openai.api_key = key"
      ],
      "metadata": {
        "id": "-1en_WicWJ3f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First test\n",
        "To check if it works and see what information we get."
      ],
      "metadata": {
        "id": "vxdff8lMpxT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import math\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Effectuer une requête avec l'API de complétion pour obtenir les logprobs\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # Ou \"gpt-4\" si vous y avez accès\n",
        "    prompt=\"Le chat mange...\",  # Votre texte d'entrée\n",
        "    max_tokens=25,  # Nombre maximal de tokens pour la réponse\n",
        "    logprobs=5,  # Demander les logprobs pour les 5 meilleurs tokens\n",
        "    top_p=1,\n",
        "    presence_penalty=0.5,\n",
        "    frequency_penalty=0.5,\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "print(response['choices'][0][\"text\"], end=\"\\n\\n\")\n",
        "print([i for i in response['choices'][0]])\n",
        "print([i for i in response['choices'][0][\"logprobs\"]])\n",
        "print(response['choices'][0][\"logprobs\"][\"tokens\"])\n",
        "print([round(np.exp(i),3) for i in response['choices'][0][\"logprobs\"][\"token_logprobs\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlKUoDlGn-xH",
        "outputId": "5f98d989-db66-438c-87db-5a22823f62f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "de la nourriture.\n",
            "\n",
            "['text', 'index', 'logprobs', 'finish_reason']\n",
            "['tokens', 'token_logprobs', 'top_logprobs', 'text_offset']\n",
            "['\\n', 'de', ' la', ' nour', 'rit', 'ure', '.']\n",
            "[0.234, 0.382, 0.998, 0.986, 1.0, 1.0, 0.762]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we can get ?\n",
        "So, we can get :\n",
        "1. The text > The actual output\n",
        "2. the logprobs\n",
        "  1. The tokens (of the output)\n",
        "  2. their corresponding logprobs\n",
        "  3. top other tokens with their respective logprobs"
      ],
      "metadata": {
        "id": "G6usL_t-qLu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Les autres suggestions\n",
        "top_five = response['choices'][0][\"logprobs\"][\"top_logprobs\"]\n",
        "for k in range(len(top_five)) :\n",
        "  print('Suggestion n°'+str(k)+\"\\t\", *[(i[0], round(np.exp(i[1]),3)) for i in top_five[k].items()], sep=\",\\t\", end=\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn1R541Ar-YQ",
        "outputId": "4538d641-c619-4fbb-a22c-d247c0edb1e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestion n°0\t,\t('\\n\\n', 0.256),\t('\\n', 0.234),\t(' des', 0.035),\t(' du', 0.019),\t(' un', 0.018)\n",
            "\n",
            "Suggestion n°1\t,\t('de', 0.382),\t('des', 0.14),\t('La', 0.108),\t('...', 0.075),\t('du', 0.073)\n",
            "\n",
            "Suggestion n°2\t,\t(' la', 0.998),\t(' tout', 0.001),\t(' l', 0.0),\t(' cro', 0.0),\t(' sour', 0.0)\n",
            "\n",
            "Suggestion n°3\t,\t(' nour', 0.986),\t(' vi', 0.01),\t(' p', 0.001),\t(' sour', 0.001),\t(' cro', 0.0)\n",
            "\n",
            "Suggestion n°4\t,\t('rit', 1.0),\t('r', 0.0),\t('ri', 0.0),\t('iture', 0.0),\t('<|endoftext|>', 0.0)\n",
            "\n",
            "Suggestion n°5\t,\t('ure', 1.0),\t('ur', 0.0),\t('u', 0.0),\t('<|endoftext|>', 0.0),\t('ue', 0.0)\n",
            "\n",
            "Suggestion n°6\t,\t('.', 0.762),\t(' ou', 0.148),\t(',', 0.067),\t('.\\n', 0.012),\t('<|endoftext|>', 0.004)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asking for a prompt, and output the answer"
      ],
      "metadata": {
        "id": "8rrIY-beq8X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = str(input(\"prompt ?\\n\\n\"))\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # Ou \"davinci-002\"\n",
        "    prompt=x,  # Votre texte d'entrée\n",
        "    max_tokens=50,  # Nombre maximal de tokens pour la réponse\n",
        "    logprobs=5,  # Demander les logprobs pour les 5 meilleurs tokens\n",
        "    top_p=1,\n",
        "    presence_penalty=0.5,\n",
        "    frequency_penalty=0.5\n",
        ")\n",
        "print(response['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akKw7zu2oHgp",
        "outputId": "72c4310c-aeba-4688-8bf2-437c63447e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "\n",
            "\n",
            "de la nourriture. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oz7ya3dikN3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stock objects : tokens and probabilities\n",
        "Here we create objects, tokens is a list of the output tokens, logprobs is the file of their corresponding log probabilities, probs are the probabilities"
      ],
      "metadata": {
        "id": "swGFt6hqrCsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = response['choices'][0][\"logprobs\"][\"tokens\"]\n",
        "\n",
        "logprobs = response['choices'][0][\"logprobs\"][\"token_logprobs\"]\n",
        "\n",
        "probs = [np.exp(i) for i in logprobs]\n",
        "\n",
        "print(*[(j, round(probs[i],2)) for i, j in enumerate(tokens)], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_k-W_OUoHaX",
        "outputId": "656776be-cb55-459c-a907-fe5224fa31f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n\\n', 0.37)\n",
            "('de', 0.61)\n",
            "(' la', 1.0)\n",
            "(' nour', 0.89)\n",
            "('rit', 1.0)\n",
            "('ure', 1.0)\n",
            "('.', 0.36)\n",
            "(' ', 0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgRDDGrIrcaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2Znn5iGrcV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We do the same with the top other candidates"
      ],
      "metadata": {
        "id": "CSRNkIDPrc9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Les autres suggestions\n",
        "top_five = response['choices'][0][\"logprobs\"][\"top_logprobs\"]\n",
        "for k in range(len(top_five)) :\n",
        "  print('Suggestion n°'+str(k)+\"\\t\", *[(i[0], round(np.exp(i[1]),3)) for i in top_five[k].items()], sep=\",  \", end=\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LBy7p8KtvbV",
        "outputId": "2e5274b9-947f-4ff1-c394-2807d1e70d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestion n°0\t,  ('\\n\\n', 0.365),  ('\\n', 0.25),  (' du', 0.012),  (' la', 0.012),  (' le', 0.01)\n",
            "\n",
            "Suggestion n°1\t,  ('de', 0.607),  ('du', 0.086),  ('des', 0.079),  ('De', 0.054),  ('...', 0.031)\n",
            "\n",
            "Suggestion n°2\t,  (' la', 0.999),  (' l', 0.0),  (' tout', 0.0),  (' nombreux', 0.0),  (' cro', 0.0)\n",
            "\n",
            "Suggestion n°3\t,  (' nour', 0.893),  (' vi', 0.098),  (' p', 0.004),  (' sour', 0.003),  (' cro', 0.001)\n",
            "\n",
            "Suggestion n°4\t,  ('rit', 1.0),  ('r', 0.0),  ('ri', 0.0),  ('iture', 0.0),  ('<|endoftext|>', 0.0)\n",
            "\n",
            "Suggestion n°5\t,  ('ure', 1.0),  ('ur', 0.0),  ('u', 0.0),  ('<|endoftext|>', 0.0),  ('ue', 0.0)\n",
            "\n",
            "Suggestion n°6\t,  (',', 0.363),  ('.', 0.356),  (' ou', 0.177),  (' comme', 0.026),  ('.\\n', 0.014)\n",
            "\n",
            "Suggestion n°7\t,  ('<|endoftext|>', 0.874),  (' ', 0.098),  (' Il', 0.016),  (' C', 0.007),  (' \\n', 0.002)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = str(input(\"prompt ?\\n\\n\"))\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # Ou \"davinci-002\"\n",
        "    prompt=x,  # Votre texte d'entrée\n",
        "    max_tokens=50,  # Nombre maximal de tokens pour la réponse\n",
        "    logprobs=5,  # Demander les logprobs pour les 5 meilleurs tokens\n",
        "    top_p=1,\n",
        "    presence_penalty=1,\n",
        "    frequency_penalty=2\n",
        ")\n",
        "print(response['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftImj0IXWKKY",
        "outputId": "a02d980b-d54c-4cb2-d08e-8ba78c9b378e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "\n",
            "de la nourriture.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = [np.exp(i) for i in response['choices'][0][\"logprobs\"][\"token_logprobs\"]]\n",
        "\n",
        "print(*[(j, round(probs[i],2)) for i, j in enumerate(response['choices'][0][\"logprobs\"][\"tokens\"])], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99dHs96NWKT2",
        "outputId": "b748a289-3eb2-4b32-d794-122720c789bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n', 0.25)\n",
            "('de', 0.59)\n",
            "(' la', 1.0)\n",
            "(' nour', 0.99)\n",
            "('rit', 1.0)\n",
            "('ure', 1.0)\n",
            "('.', 0.82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature"
      ],
      "metadata": {
        "id": "qfOEnWrV5mpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = str(input(\"prompt ?\\n\"))\n",
        "t = float(input(\"temperature ?\\n\"))\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # Ou \"davinci-002\"\n",
        "    prompt=x,  # Votre texte d'entrée\n",
        "    max_tokens=25,  # Nombre maximal de tokens pour la réponse\n",
        "    logprobs=5,  # Demander les logprobs pour les 5 meilleurs tokens\n",
        "    top_p=1,\n",
        "    presence_penalty=0,\n",
        "    frequency_penalty=0,\n",
        "    temperature=t\n",
        ")\n",
        "print(response['choices'][0][\"text\"])\n",
        "probs = [np.exp(i) for i in response['choices'][0][\"logprobs\"][\"token_logprobs\"]]\n",
        "print(*[(j, round(probs[i],2)) for i, j in enumerate(response['choices'][0][\"logprobs\"][\"tokens\"])], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K02dWBgEnZjS",
        "outputId": "41f14a30-ba97-43f3-878f-9edaa1204533"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "Le chat mange ...\n",
            "temperature ?\n",
            "0\n",
            "\n",
            "\n",
            "de la nourriture, principalement des croquettes ou de la pâtée spécialement conçues\n",
            "('\\n\\n', 0.37)\n",
            "('de', 0.61)\n",
            "(' la', 1.0)\n",
            "(' nour', 0.89)\n",
            "('rit', 1.0)\n",
            "('ure', 1.0)\n",
            "(',', 0.36)\n",
            "(' princip', 0.28)\n",
            "('alement', 1.0)\n",
            "(' des', 0.75)\n",
            "(' cro', 0.99)\n",
            "('quet', 1.0)\n",
            "('tes', 1.0)\n",
            "(' ou', 0.86)\n",
            "(' de', 0.9)\n",
            "(' la', 1.0)\n",
            "(' p', 0.98)\n",
            "('ât', 1.0)\n",
            "('ée', 0.97)\n",
            "(' spéc', 0.55)\n",
            "('ia', 0.99)\n",
            "('lement', 1.0)\n",
            "(' con', 0.97)\n",
            "('ç', 1.0)\n",
            "('ues', 0.71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presence penalty, frequency penalty, temperature"
      ],
      "metadata": {
        "id": "oo0GVrbdrnUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  x = str(input(\"prompt ?\\n\\n\"))\n",
        "  p = float(input(\"penalty ?\\n\\n\"))\n",
        "  f = float(input(\"frequency ?\\n\\n\"))\n",
        "  t = float(input(\"temperature ?\\n\\n\"))\n",
        "  response = openai.Completion.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",  # Ou \"davinci-002\"\n",
        "      prompt=x,  # Votre texte d'entrée\n",
        "      max_tokens=25,  # Nombre maximal de tokens pour la réponse\n",
        "      logprobs=5,  # Demander les logprobs pour les 5 meilleurs tokens\n",
        "      top_p=1,\n",
        "      presence_penalty=p,\n",
        "      frequency_penalty=f,\n",
        "      temperature=t\n",
        "  )\n",
        "  print(response['choices'][0][\"text\"], end=\"\\n\")\n",
        "  #probs = [np.exp(i) for i in response['choices'][0][\"logprobs\"][\"token_logprobs\"]]\n",
        "  #print(*[(j, round(probs[i],2)) for i, j in enumerate(response['choices'][0][\"logprobs\"][\"tokens\"])], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "l1OknzgMuX7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSAk8WOjuX5B",
        "outputId": "6e256245-5963-4a00-db3f-49fa08a4e000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "penalty ?\n",
            "\n",
            "0\n",
            "frequency ?\n",
            "\n",
            "0\n",
            "temperature ?\n",
            "\n",
            "0\n",
            "\n",
            "\n",
            "de la nourriture, principalement des croquettes ou de la pâtée spécialement conçues\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6fu-eSF7YNB",
        "outputId": "6e504bd4-6c77-44bd-e218-f913a7919948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "penalty ?\n",
            "\n",
            "0\n",
            "frequency ?\n",
            "\n",
            "2\n",
            "temperature ?\n",
            "\n",
            "0\n",
            "\n",
            "\n",
            "de la nourriture, principalement des croquettes ou de la pâtée spécialement conçues\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6vcZMWj7YKN",
        "outputId": "2fdc1188-fd3e-4cee-881b-e9a2b965df2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "penalty ?\n",
            "\n",
            "0\n",
            "frequency ?\n",
            "\n",
            "0\n",
            "temperature ?\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "de la nourriture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-uIoP_-7YG1",
        "outputId": "e27a2125-7875-4b08-f31b-aa76bee2b21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "penalty ?\n",
            "\n",
            "2\n",
            "frequency ?\n",
            "\n",
            "0\n",
            "temperature ?\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "des croquettes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R7vdo3t7YDs",
        "outputId": "8e94cca6-0c83-46b1-ebe5-749102b7219b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt ?\n",
            "\n",
            "Le chat mange ...\n",
            "penalty ?\n",
            "\n",
            "0\n",
            "frequency ?\n",
            "\n",
            "2\n",
            "temperature ?\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "de la nourriture.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrGlVgCl7YA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Al4vpghJuX18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Le_y8wFYuXzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cENDE-H_8GxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iaOYWeTc8Gn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJE7qVFu8Gkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TjmRKch8Gh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgS3n6B_8Gfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qed9caDj8Gcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwYNqJZk8GZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uO_i479M8GWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1JYeXL_8GTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CftC2AYr8GQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ibXFksN8GOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbDIGgTZ8GKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5sNwOlPP8GHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3F-_rcdw8GDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z7ZsSI1g8GBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9_VopM-8F97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAJVMuCu8F6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sogSe4Cu8F3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSFXGYXG8F0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZA6PY5ks8Fxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BR6hQvNp8Fuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REt_BX1suXwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQ-W6sFguXtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "es57sEnwuXpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyxNnIQDuch3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "***\n",
        "<h1>Draft</h1>\n",
        "\n",
        "***\n",
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "IOgoev1vuc6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWs0OhXBuXly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import math\n",
        "import json\n",
        "\n",
        "# Effectuer une requête avec l'API de complétion pour obtenir les logprobs\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # Ou \"gpt-4\" si vous y avez accès\n",
        "    prompt=\"Le chat mange...\",  # Votre texte d'entrée\n",
        "    max_tokens=50,  # Nombre maximal de tokens pour la réponse\n",
        "    logprobs=5,  # Demander les logprobs pour les 5 meilleurs tokens\n",
        "    top_p=1,\n",
        "    presence_penalty=0.5,\n",
        "    frequency_penalty=0.5\n",
        ")\n",
        "\n",
        "def transformer_logprobs_en_liste(choice_logprobs):\n",
        "    \"\"\"\n",
        "    Transforme les logprobs en une structure liste de listes.\n",
        "\n",
        "    Args:\n",
        "        choice_logprobs (list): Liste des logprobs par token.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionnaire où chaque token est une clé et la valeur est une liste de tuples (token, probabilité).\n",
        "    \"\"\"\n",
        "    resultat = {}\n",
        "    for idx, token_logprob in enumerate(choice_logprobs):\n",
        "        token_cle = f\"token_{idx + 1}\"\n",
        "        candidats = []\n",
        "        for token, logprob in token_logprob.items():\n",
        "            proba = math.exp(logprob)  # Convertir logprob en probabilité\n",
        "            candidats.append((token, proba))\n",
        "        resultat[token_cle] = candidats\n",
        "    return resultat\n",
        "\n",
        "# Afficher la réponse générée et les logprobs transformés\n",
        "for choice in response['choices']:\n",
        "    print(f\"Texte généré : {choice['text']}\")\n",
        "    if 'logprobs' in choice:\n",
        "        # Transformer les logprobs\n",
        "        logprobs_top = choice['logprobs']['top_logprobs']\n",
        "        resultat_structure = transformer_logprobs_en_liste(logprobs_top)\n",
        "\n",
        "        # Affichage en JSON pour lisibilité\n",
        "        print(\"Logprobs structurés :\")\n",
        "        print(json.dumps(resultat_structure, indent=4, ensure_ascii=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7uGzU0LXw1R",
        "outputId": "d9514252-6c5b-4f0d-f57a-64d1c7c90f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texte généré : \n",
            "Il mange de la nourriture, comme des croquettes, du poisson, ou de la viande.\n",
            "Logprobs structurés :\n",
            "{\n",
            "    \"token_1\": [\n",
            "        [\n",
            "            \"\\n\\n\",\n",
            "            0.25575165576932496\n",
            "        ],\n",
            "        [\n",
            "            \"\\n\",\n",
            "            0.23444126301934132\n",
            "        ],\n",
            "        [\n",
            "            \" des\",\n",
            "            0.03496629435225372\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.019341075120310296\n",
            "        ],\n",
            "        [\n",
            "            \" un\",\n",
            "            0.018130983655608286\n",
            "        ]\n",
            "    ],\n",
            "    \"token_2\": [\n",
            "        [\n",
            "            \"de\",\n",
            "            0.34860785958802143\n",
            "        ],\n",
            "        [\n",
            "            \"des\",\n",
            "            0.13337090136389648\n",
            "        ],\n",
            "        [\n",
            "            \"La\",\n",
            "            0.11102081197217717\n",
            "        ],\n",
            "        [\n",
            "            \"du\",\n",
            "            0.08739406541991676\n",
            "        ],\n",
            "        [\n",
            "            \"...\",\n",
            "            0.08180323405747644\n",
            "        ]\n",
            "    ],\n",
            "    \"token_3\": [\n",
            "        [\n",
            "            \" mange\",\n",
            "            0.8110580168520024\n",
            "        ],\n",
            "        [\n",
            "            \" n\",\n",
            "            0.07996508316678612\n",
            "        ],\n",
            "        [\n",
            "            \" dé\",\n",
            "            0.02807959283802468\n",
            "        ],\n",
            "        [\n",
            "            \" y\",\n",
            "            0.02408890302311761\n",
            "        ],\n",
            "        [\n",
            "            \" est\",\n",
            "            0.021455992542814325\n",
            "        ]\n",
            "    ],\n",
            "    \"token_4\": [\n",
            "        [\n",
            "            \" de\",\n",
            "            0.649102830694088\n",
            "        ],\n",
            "        [\n",
            "            \" des\",\n",
            "            0.14731541656384642\n",
            "        ],\n",
            "        [\n",
            "            \" une\",\n",
            "            0.0632530772742938\n",
            "        ],\n",
            "        [\n",
            "            \" sa\",\n",
            "            0.05708393216963436\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.023175736224206753\n",
            "        ]\n",
            "    ],\n",
            "    \"token_5\": [\n",
            "        [\n",
            "            \" la\",\n",
            "            0.9989435747105101\n",
            "        ],\n",
            "        [\n",
            "            \" tout\",\n",
            "            0.0006114462532469824\n",
            "        ],\n",
            "        [\n",
            "            \" l\",\n",
            "            0.0002798524662245064\n",
            "        ],\n",
            "        [\n",
            "            \" cro\",\n",
            "            3.6160796340209845e-05\n",
            "        ],\n",
            "        [\n",
            "            \" nombreux\",\n",
            "            2.6817872724938833e-05\n",
            "        ]\n",
            "    ],\n",
            "    \"token_6\": [\n",
            "        [\n",
            "            \" nour\",\n",
            "            0.9937548703941953\n",
            "        ],\n",
            "        [\n",
            "            \" vi\",\n",
            "            0.0050157566077732845\n",
            "        ],\n",
            "        [\n",
            "            \" p\",\n",
            "            0.0006779215396163866\n",
            "        ],\n",
            "        [\n",
            "            \" cro\",\n",
            "            0.0002473624223007924\n",
            "        ],\n",
            "        [\n",
            "            \" sour\",\n",
            "            0.00018305260269626232\n",
            "        ]\n",
            "    ],\n",
            "    \"token_7\": [\n",
            "        [\n",
            "            \"rit\",\n",
            "            0.9998221005559831\n",
            "        ],\n",
            "        [\n",
            "            \"r\",\n",
            "            8.381655636521375e-05\n",
            "        ],\n",
            "        [\n",
            "            \"ri\",\n",
            "            6.887887711670244e-05\n",
            "        ],\n",
            "        [\n",
            "            \"iture\",\n",
            "            1.851848751014468e-05\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            3.2774856488702116e-06\n",
            "        ]\n",
            "    ],\n",
            "    \"token_8\": [\n",
            "        [\n",
            "            \"ure\",\n",
            "            0.9998611895050684\n",
            "        ],\n",
            "        [\n",
            "            \"ur\",\n",
            "            8.239045212763453e-05\n",
            "        ],\n",
            "        [\n",
            "            \"u\",\n",
            "            5.150554943914256e-05\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            2.9595184164801606e-06\n",
            "        ],\n",
            "        [\n",
            "            \"urre\",\n",
            "            3.7367514994629094e-07\n",
            "        ]\n",
            "    ],\n",
            "    \"token_9\": [\n",
            "        [\n",
            "            \",\",\n",
            "            0.48381353730343596\n",
            "        ],\n",
            "        [\n",
            "            \".\",\n",
            "            0.1556457480260898\n",
            "        ],\n",
            "        [\n",
            "            \" ou\",\n",
            "            0.14271337939423612\n",
            "        ],\n",
            "        [\n",
            "            \" pour\",\n",
            "            0.10221856132924982\n",
            "        ],\n",
            "        [\n",
            "            \" spéc\",\n",
            "            0.05809160603513526\n",
            "        ]\n",
            "    ],\n",
            "    \"token_10\": [\n",
            "        [\n",
            "            \" comme\",\n",
            "            0.588565275497703\n",
            "        ],\n",
            "        [\n",
            "            \" des\",\n",
            "            0.19371063608185485\n",
            "        ],\n",
            "        [\n",
            "            \" géné\",\n",
            "            0.07789088047745277\n",
            "        ],\n",
            "        [\n",
            "            \" de\",\n",
            "            0.038924476900641186\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.03620273176051314\n",
            "        ]\n",
            "    ],\n",
            "    \"token_11\": [\n",
            "        [\n",
            "            \" des\",\n",
            "            0.9713474749763803\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.017171739479035834\n",
            "        ],\n",
            "        [\n",
            "            \" de\",\n",
            "            0.009985666142681518\n",
            "        ],\n",
            "        [\n",
            "            \" par\",\n",
            "            0.0007395704598205289\n",
            "        ],\n",
            "        [\n",
            "            \" les\",\n",
            "            0.0003139436646798068\n",
            "        ]\n",
            "    ],\n",
            "    \"token_12\": [\n",
            "        [\n",
            "            \" cro\",\n",
            "            0.9999758467426946\n",
            "        ],\n",
            "        [\n",
            "            \" biscuits\",\n",
            "            8.396278382440425e-06\n",
            "        ],\n",
            "        [\n",
            "            \" al\",\n",
            "            3.4341641336315837e-06\n",
            "        ],\n",
            "        [\n",
            "            \" sour\",\n",
            "            2.8236716961381252e-06\n",
            "        ],\n",
            "        [\n",
            "            \" gran\",\n",
            "            1.607211288121547e-06\n",
            "        ]\n",
            "    ],\n",
            "    \"token_13\": [\n",
            "        [\n",
            "            \"quet\",\n",
            "            0.9999944422379444\n",
            "        ],\n",
            "        [\n",
            "            \"quette\",\n",
            "            3.897594461011106e-06\n",
            "        ],\n",
            "        [\n",
            "            \"q\",\n",
            "            7.974011179549116e-07\n",
            "        ],\n",
            "        [\n",
            "            \"qu\",\n",
            "            3.593604187970705e-07\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            1.649703625646311e-07\n",
            "        ]\n",
            "    ],\n",
            "    \"token_14\": [\n",
            "        [\n",
            "            \"tes\",\n",
            "            0.9997921898755158\n",
            "        ],\n",
            "        [\n",
            "            \"t\",\n",
            "            0.00011746031806682919\n",
            "        ],\n",
            "        [\n",
            "            \"te\",\n",
            "            8.273531679461474e-05\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            5.560019180374996e-06\n",
            "        ],\n",
            "        [\n",
            "            \"es\",\n",
            "            9.305844568166785e-07\n",
            "        ]\n",
            "    ],\n",
            "    \"token_15\": [\n",
            "        [\n",
            "            \" ou\",\n",
            "            0.5675574280185947\n",
            "        ],\n",
            "        [\n",
            "            \",\",\n",
            "            0.42654278523539846\n",
            "        ],\n",
            "        [\n",
            "            \" pour\",\n",
            "            0.00509932041546645\n",
            "        ],\n",
            "        [\n",
            "            \" spéc\",\n",
            "            0.0006415575925474713\n",
            "        ],\n",
            "        [\n",
            "            \" de\",\n",
            "            8.482900784639115e-05\n",
            "        ]\n",
            "    ],\n",
            "    \"token_16\": [\n",
            "        [\n",
            "            \" de\",\n",
            "            0.6954415022989887\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.2401438644551228\n",
            "        ],\n",
            "        [\n",
            "            \" des\",\n",
            "            0.06229912488980411\n",
            "        ],\n",
            "        [\n",
            "            \" ou\",\n",
            "            0.0014211953012610598\n",
            "        ],\n",
            "        [\n",
            "            \" une\",\n",
            "            0.0002701803119021155\n",
            "        ]\n",
            "    ],\n",
            "    \"token_17\": [\n",
            "        [\n",
            "            \" po\",\n",
            "            0.7804223901791626\n",
            "        ],\n",
            "        [\n",
            "            \" p\",\n",
            "            0.18260796350961006\n",
            "        ],\n",
            "        [\n",
            "            \" th\",\n",
            "            0.02164158681125921\n",
            "        ],\n",
            "        [\n",
            "            \" pou\",\n",
            "            0.011299627708014355\n",
            "        ],\n",
            "        [\n",
            "            \" la\",\n",
            "            0.0021474267803155943\n",
            "        ]\n",
            "    ],\n",
            "    \"token_18\": [\n",
            "        [\n",
            "            \"isson\",\n",
            "            0.9997743168702697\n",
            "        ],\n",
            "        [\n",
            "            \"i\",\n",
            "            0.00013086804925282433\n",
            "        ],\n",
            "        [\n",
            "            \"is\",\n",
            "            4.491754869687069e-05\n",
            "        ],\n",
            "        [\n",
            "            \"iss\",\n",
            "            2.9447633724742568e-05\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            1.6484862869118316e-05\n",
            "        ]\n",
            "    ],\n",
            "    \"token_19\": [\n",
            "        [\n",
            "            \" ou\",\n",
            "            0.8666883714270321\n",
            "        ],\n",
            "        [\n",
            "            \",\",\n",
            "            0.13316930371822494\n",
            "        ],\n",
            "        [\n",
            "            \" en\",\n",
            "            6.382893141153012e-05\n",
            "        ],\n",
            "        [\n",
            "            \" et\",\n",
            "            2.4426718604325147e-05\n",
            "        ],\n",
            "        [\n",
            "            \" \",\n",
            "            1.7291059187913994e-05\n",
            "        ]\n",
            "    ],\n",
            "    \"token_20\": [\n",
            "        [\n",
            "            \" de\",\n",
            "            0.6490876808108195\n",
            "        ],\n",
            "        [\n",
            "            \" ou\",\n",
            "            0.3255300506791365\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.01660856089482494\n",
            "        ],\n",
            "        [\n",
            "            \" des\",\n",
            "            0.008404665589534482\n",
            "        ],\n",
            "        [\n",
            "            \" \",\n",
            "            0.00018799616392439056\n",
            "        ]\n",
            "    ],\n",
            "    \"token_21\": [\n",
            "        [\n",
            "            \" de\",\n",
            "            0.8280102379495083\n",
            "        ],\n",
            "        [\n",
            "            \" encore\",\n",
            "            0.12183091965133652\n",
            "        ],\n",
            "        [\n",
            "            \" des\",\n",
            "            0.03503567327965722\n",
            "        ],\n",
            "        [\n",
            "            \" du\",\n",
            "            0.005784286281107453\n",
            "        ],\n",
            "        [\n",
            "            \" même\",\n",
            "            0.003955291406285715\n",
            "        ]\n",
            "    ],\n",
            "    \"token_22\": [\n",
            "        [\n",
            "            \" la\",\n",
            "            0.9998586865756827\n",
            "        ],\n",
            "        [\n",
            "            \" l\",\n",
            "            0.00011244155302367822\n",
            "        ],\n",
            "        [\n",
            "            \" \",\n",
            "            9.755678814456143e-06\n",
            "        ],\n",
            "        [\n",
            "            \" vi\",\n",
            "            6.843118562803453e-06\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            3.4390131594073238e-06\n",
            "        ]\n",
            "    ],\n",
            "    \"token_23\": [\n",
            "        [\n",
            "            \" vi\",\n",
            "            0.9938398808154502\n",
            "        ],\n",
            "        [\n",
            "            \" p\",\n",
            "            0.0057837790214442615\n",
            "        ],\n",
            "        [\n",
            "            \" vol\",\n",
            "            0.00028824925020942926\n",
            "        ],\n",
            "        [\n",
            "            \" nour\",\n",
            "            4.124626478294633e-05\n",
            "        ],\n",
            "        [\n",
            "            \" pat\",\n",
            "            1.55296260545833e-05\n",
            "        ]\n",
            "    ],\n",
            "    \"token_24\": [\n",
            "        [\n",
            "            \"ande\",\n",
            "            0.9992603314397577\n",
            "        ],\n",
            "        [\n",
            "            \"a\",\n",
            "            0.0003240920427351005\n",
            "        ],\n",
            "        [\n",
            "            \"an\",\n",
            "            0.0002809876049785614\n",
            "        ],\n",
            "        [\n",
            "            \"and\",\n",
            "            0.0001035386070329985\n",
            "        ],\n",
            "        [\n",
            "            \"<|endoftext|>\",\n",
            "            1.31964988789043e-05\n",
            "        ]\n",
            "    ],\n",
            "    \"token_25\": [\n",
            "        [\n",
            "            \".\",\n",
            "            0.9904455698988481\n",
            "        ],\n",
            "        [\n",
            "            \".\\n\",\n",
            "            0.007845455751231375\n",
            "        ],\n",
            "        [\n",
            "            \" cr\",\n",
            "            0.0007807715191727501\n",
            "        ],\n",
            "        [\n",
            "            \",\",\n",
            "            0.00031589300294184656\n",
            "        ],\n",
            "        [\n",
            "            \".\\n\\n\",\n",
            "            0.00018237072356089046\n",
            "        ]\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response['choices'][0][\"logprobs\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve8BuxxabGM5",
        "outputId": "11b18106-7d0f-41ab-cb03-31db114db5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7a4ba1f1a8e0> JSON: {\n",
              "  \"tokens\": [\n",
              "    \"\\n\",\n",
              "    \"Il\",\n",
              "    \" mange\",\n",
              "    \" de\",\n",
              "    \" la\",\n",
              "    \" nour\",\n",
              "    \"rit\",\n",
              "    \"ure\",\n",
              "    \",\",\n",
              "    \" comme\",\n",
              "    \" des\",\n",
              "    \" cro\",\n",
              "    \"quet\",\n",
              "    \"tes\",\n",
              "    \",\",\n",
              "    \" du\",\n",
              "    \" po\",\n",
              "    \"isson\",\n",
              "    \",\",\n",
              "    \" ou\",\n",
              "    \" de\",\n",
              "    \" la\",\n",
              "    \" vi\",\n",
              "    \"ande\",\n",
              "    \".\"\n",
              "  ],\n",
              "  \"token_logprobs\": [\n",
              "    -1.4505502,\n",
              "    -3.8228374,\n",
              "    -0.20941569,\n",
              "    -0.43216413,\n",
              "    -0.0010569837,\n",
              "    -0.006264712,\n",
              "    -0.00017791527,\n",
              "    -0.00013882013,\n",
              "    -0.7260557,\n",
              "    -0.53006744,\n",
              "    -0.029071022,\n",
              "    -2.4153549e-05,\n",
              "    -5.5577775e-06,\n",
              "    -0.00020783172,\n",
              "    -0.8520426,\n",
              "    -1.4265171,\n",
              "    -0.24791998,\n",
              "    -0.0002257086,\n",
              "    -2.016134,\n",
              "    -1.1223005,\n",
              "    -0.18872976,\n",
              "    -0.00014132341,\n",
              "    -0.006179171,\n",
              "    -0.00073994225,\n",
              "    -0.0096003665\n",
              "  ],\n",
              "  \"top_logprobs\": [\n",
              "    {\n",
              "      \"\\n\\n\": -1.3635484,\n",
              "      \"\\n\": -1.4505502,\n",
              "      \" des\": -3.3533707,\n",
              "      \" du\": -3.9455242,\n",
              "      \" un\": -4.010133\n",
              "    },\n",
              "    {\n",
              "      \"de\": -1.0538076,\n",
              "      \"des\": -2.0146213,\n",
              "      \"La\": -2.1980376,\n",
              "      \"du\": -2.4373279,\n",
              "      \"...\": -2.5034385\n",
              "    },\n",
              "    {\n",
              "      \" mange\": -0.20941569,\n",
              "      \" n\": -2.5261652,\n",
              "      \" d\\u00e9\": -3.5727122,\n",
              "      \" y\": -3.726004,\n",
              "      \" est\": -3.8417513\n",
              "    },\n",
              "    {\n",
              "      \" de\": -0.43216413,\n",
              "      \" des\": -1.9151793,\n",
              "      \" une\": -2.7606115,\n",
              "      \" sa\": -2.8632326,\n",
              "      \" du\": -3.7646494\n",
              "    },\n",
              "    {\n",
              "      \" la\": -0.0010569837,\n",
              "      \" tout\": -7.3996835,\n",
              "      \" l\": -8.181248,\n",
              "      \" cro\": -10.227535,\n",
              "      \" nombreux\": -10.526442\n",
              "    },\n",
              "    {\n",
              "      \" nour\": -0.006264712,\n",
              "      \" vi\": -5.295171,\n",
              "      \" p\": -7.296479,\n",
              "      \" cro\": -8.304656,\n",
              "      \" sour\": -8.605737\n",
              "    },\n",
              "    {\n",
              "      \"rit\": -0.00017791527,\n",
              "      \"r\": -9.38688,\n",
              "      \"ri\": -9.583161,\n",
              "      \"iture\": -10.896741,\n",
              "      \"<|endoftext|>\": -12.628434\n",
              "    },\n",
              "    {\n",
              "      \"ure\": -0.00013882013,\n",
              "      \"ur\": -9.404041,\n",
              "      \"u\": -9.873821,\n",
              "      \"<|endoftext|>\": -12.730484,\n",
              "      \"urre\": -14.799879\n",
              "    },\n",
              "    {\n",
              "      \",\": -0.7260557,\n",
              "      \".\": -1.8601727,\n",
              "      \" ou\": -1.946917,\n",
              "      \" pour\": -2.280642,\n",
              "      \" sp\\u00e9c\": -2.8457341\n",
              "    },\n",
              "    {\n",
              "      \" comme\": -0.53006744,\n",
              "      \" des\": -1.6413898,\n",
              "      \" g\\u00e9n\\u00e9\": -2.5524464,\n",
              "      \" de\": -3.246132,\n",
              "      \" du\": -3.3186207\n",
              "    },\n",
              "    {\n",
              "      \" des\": -0.029071022,\n",
              "      \" du\": -4.0644903,\n",
              "      \" de\": -4.6066046,\n",
              "      \" par\": -7.209441,\n",
              "      \" les\": -8.066297\n",
              "    },\n",
              "    {\n",
              "      \" cro\": -2.4153549e-05,\n",
              "      \" biscuits\": -11.687722,\n",
              "      \" al\": -12.581737,\n",
              "      \" sour\": -12.7774725,\n",
              "      \" gran\": -13.34101\n",
              "    },\n",
              "    {\n",
              "      \"quet\": -5.5577775e-06,\n",
              "      \"quette\": -12.455151,\n",
              "      \"q\": -14.041908,\n",
              "      \"qu\": -14.83894,\n",
              "      \"<|endoftext|>\": -15.6175\n",
              "    },\n",
              "    {\n",
              "      \"tes\": -0.00020783172,\n",
              "      \"t\": -9.04941,\n",
              "      \"te\": -9.399864,\n",
              "      \"<|endoftext|>\": -12.099909,\n",
              "      \"es\": -13.887453\n",
              "    },\n",
              "    {\n",
              "      \" ou\": -0.56641334,\n",
              "      \",\": -0.8520426,\n",
              "      \" pour\": -5.278648,\n",
              "      \" sp\\u00e9c\": -7.3516116,\n",
              "      \" de\": -9.374873\n",
              "    },\n",
              "    {\n",
              "      \" de\": -0.36320838,\n",
              "      \" du\": -1.4265171,\n",
              "      \" des\": -2.7758079,\n",
              "      \" ou\": -6.556257,\n",
              "      \" une\": -8.216421\n",
              "    },\n",
              "    {\n",
              "      \" po\": -0.24791998,\n",
              "      \" p\": -1.7004137,\n",
              "      \" th\": -3.8331385,\n",
              "      \" pou\": -4.4829855,\n",
              "      \" la\": -6.143485\n",
              "    },\n",
              "    {\n",
              "      \"isson\": -0.0002257086,\n",
              "      \"i\": -8.941321,\n",
              "      \"is\": -10.010682,\n",
              "      \"iss\": -10.432897,\n",
              "      \"<|endoftext|>\": -11.013068\n",
              "    },\n",
              "    {\n",
              "      \" ou\": -0.1430758,\n",
              "      \",\": -2.016134,\n",
              "      \" en\": -9.659304,\n",
              "      \" et\": -10.619833,\n",
              "      \" \": -10.965321\n",
              "    },\n",
              "    {\n",
              "      \" de\": -0.43218747,\n",
              "      \" ou\": -1.1223005,\n",
              "      \" du\": -4.097837,\n",
              "      \" des\": -4.7789683,\n",
              "      \" \": -8.579089\n",
              "    },\n",
              "    {\n",
              "      \" de\": -0.18872976,\n",
              "      \" encore\": -2.1051211,\n",
              "      \" des\": -3.3513885,\n",
              "      \" du\": -5.1526103,\n",
              "      \" m\\u00eame\": -5.532701\n",
              "    },\n",
              "    {\n",
              "      \" la\": -0.00014132341,\n",
              "      \" l\": -9.093077,\n",
              "      \" \": -11.537661,\n",
              "      \" vi\": -11.892267,\n",
              "      \"<|endoftext|>\": -12.580326\n",
              "    },\n",
              "    {\n",
              "      \" vi\": -0.006179171,\n",
              "      \" p\": -5.152698,\n",
              "      \" vol\": -8.151685,\n",
              "      \" nour\": -10.09595,\n",
              "      \" pat\": -11.072761\n",
              "    },\n",
              "    {\n",
              "      \"ande\": -0.00073994225,\n",
              "      \"a\": -8.034483,\n",
              "      \"an\": -8.1772,\n",
              "      \"and\": -9.175566,\n",
              "      \"<|endoftext|>\": -11.235559\n",
              "    },\n",
              "    {\n",
              "      \".\": -0.0096003665,\n",
              "      \".\\n\": -4.8478208,\n",
              "      \" cr\": -7.155228,\n",
              "      \",\": -8.060107,\n",
              "      \".\\n\\n\": -8.609469\n",
              "    }\n",
              "  ],\n",
              "  \"text_offset\": [\n",
              "    16,\n",
              "    17,\n",
              "    19,\n",
              "    25,\n",
              "    28,\n",
              "    31,\n",
              "    36,\n",
              "    39,\n",
              "    42,\n",
              "    43,\n",
              "    49,\n",
              "    53,\n",
              "    57,\n",
              "    61,\n",
              "    64,\n",
              "    65,\n",
              "    68,\n",
              "    71,\n",
              "    76,\n",
              "    77,\n",
              "    80,\n",
              "    83,\n",
              "    86,\n",
              "    89,\n",
              "    93\n",
              "  ]\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jodi236Gnrua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([i for i in response['choices'][0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-KNYIsfZ41r",
        "outputId": "bbc9cfeb-4c3d-4596-d1ee-c6840c2ce499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'index', 'logprobs', 'finish_reason']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7gYdT1ahB5",
        "outputId": "51bba994-f29e-4ae6-bc14-3a3783734083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Il mange de la nourriture, comme des croquettes, du poisson, ou de la viande.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([i for i in response['choices'][0][\"logprobs\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ynrqMMbMvi",
        "outputId": "85cfedb7-b0c9-4c1c-cb6e-5145f78fdd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokens', 'token_logprobs', 'top_logprobs', 'text_offset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response['choices'][0][\"logprobs\"][\"tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcAyQta5bU8C",
        "outputId": "0b22fe16-a0f1-4cf7-841e-ee1cbc9f8786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " 'Il',\n",
              " ' mange',\n",
              " ' de',\n",
              " ' la',\n",
              " ' nour',\n",
              " 'rit',\n",
              " 'ure',\n",
              " ',',\n",
              " ' comme',\n",
              " ' des',\n",
              " ' cro',\n",
              " 'quet',\n",
              " 'tes',\n",
              " ',',\n",
              " ' du',\n",
              " ' po',\n",
              " 'isson',\n",
              " ',',\n",
              " ' ou',\n",
              " ' de',\n",
              " ' la',\n",
              " ' vi',\n",
              " 'ande',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[np.exp(i) for i in response['choices'][0][\"logprobs\"][\"token_logprobs\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SXD6ZTWbiPX",
        "outputId": "a9e0f42c-a8f1-4c0e-edd9-296e49940b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23444126301934132,\n",
              " 0.021865671137173668,\n",
              " 0.8110580168520024,\n",
              " 0.649102830694088,\n",
              " 0.9989435747105101,\n",
              " 0.9937548703941953,\n",
              " 0.9998221005559831,\n",
              " 0.9998611895050684,\n",
              " 0.48381353730343596,\n",
              " 0.588565275497703,\n",
              " 0.9713474749763803,\n",
              " 0.9999758467426946,\n",
              " 0.9999944422379444,\n",
              " 0.9997921898755158,\n",
              " 0.42654278523539846,\n",
              " 0.2401438644551228,\n",
              " 0.7804223901791626,\n",
              " 0.9997743168702697,\n",
              " 0.13316930371822494,\n",
              " 0.3255300506791365,\n",
              " 0.8280102379495083,\n",
              " 0.9998586865756827,\n",
              " 0.9938398808154502,\n",
              " 0.9992603314397577,\n",
              " 0.9904455698988481]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQUD6fmxbuI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}