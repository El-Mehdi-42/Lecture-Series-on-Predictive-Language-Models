{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MBLqlgL3BYi"
   },
   "source": [
    "# Working with pre-trained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9P1gOVRYXsAP"
   },
   "source": [
    "## Loading the vectors\n",
    "\n",
    "We download a small set of French word vectors trained with **Skip-Gram**.\n",
    "\n",
    "The training corpus is the entire French Wikipedia and the vocabulary corresponds to the 100,000 most frequent words. Each word in the vocabulary is mapped to a vector $u \\in \\mathbb{R}^{300}$.\n",
    "\n",
    "You'll find word vectors in other languages (for much larger vocabularies) over here: https://fasttext.cc/docs/en/crawl-vectors.html#models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwvw-J6A1mfW"
   },
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVMVudR71lFo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L-20FIu13Nr"
   },
   "source": [
    "## Read the vocabulary and load the vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ca5OwVj2Am8"
   },
   "outputs": [],
   "source": [
    "# Download the subset of embedded words\n",
    "! unzip wiki.fr.100k.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nv5d78ocFxVo"
   },
   "outputs": [],
   "source": [
    "#! wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
    "#! wiki-news-300d-1M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDloYrrxFxVp",
    "outputId": "431604f8-2d2b-4fc0-8086-ab038d9e60f1"
   },
   "outputs": [],
   "source": [
    "## Read the vocabulary and the vectors \n",
    "data = pd.read_csv(\"wiki.fr.100k.vec\", sep=\" \", quoting=3, header=None, skiprows=1)\n",
    "vocabulary = list(data[0].values)\n",
    "vectors = data[range(1, 301)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1i141JZ2g9A"
   },
   "source": [
    "## From words to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27UlFloAIb9R"
   },
   "outputs": [],
   "source": [
    "# Simple function that returns the word vector, if it exists\n",
    "def get_vector(word):\n",
    "    word = str(word) ; word = word.lower()\n",
    "    if word in vocabulary:\n",
    "        return np.array(vectors[vocabulary.index(word)])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnJuZn6YWxMn"
   },
   "source": [
    "## Getting similar words\n",
    "\n",
    "We usually measure the similarity between word vectors in terms of the angle between them. More precisely, we rely on the cosine of this angle: $\\cos(\\theta_{u_1, u_2}) = \\frac{u_1 \\cdot u_2}{||u_1|| \\times ||u_2||}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFbPPqod-USy",
    "outputId": "1e28ad61-2ce9-4cae-bcf3-e81f576035c8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_most_similar_words(vector, n=10):\n",
    "    if type(vector) == str:\n",
    "    vector = get_vector(vector)\n",
    "    s = cosine_similarity(vector.reshape(1, -1), vectors)\n",
    "    sorted_ids = np.argsort(-s)[0]\n",
    "    return np.array([vocabulary[i] for i in sorted_ids[:n]])\n",
    "\n",
    "get_most_similar_words(\"fréjus\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6-IFwCr1ORC"
   },
   "source": [
    "## Cosine Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuSO_XyEOrvv"
   },
   "outputs": [],
   "source": [
    "## If we want to use another kernel (instead of cosine kernel) we can define it as follows\n",
    "# Appliying the kernel between two vectors\n",
    "def f(x,y):\n",
    "    return np.exp(-np.sum((x-y)**2/(x+y)))\n",
    "\n",
    "# define g that applies the kernel between a vector and a list of vectors\n",
    "def g(x,l):\n",
    "    return np.array([f(x,y) for y in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhji08qa2Q1A"
   },
   "source": [
    "### A small example applying cosine function between two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNRhp0s-O-rU",
    "outputId": "50e0a940-b973-4c11-cb27-94afc4650345"
   },
   "outputs": [],
   "source": [
    "# define two lists or array\n",
    "Vector1 = np.array([2,1,2,3,2,9])\n",
    "Vector2 = np.array([3,4,2,4,5,5])\n",
    " \n",
    "print(\"Vector1:\", Vector1)\n",
    "print(\"Vector2:\", Vector2)\n",
    " \n",
    "# compute cosine similarity\n",
    "cosine_value = np.dot(Vector1,Vector2)/(norm(Vector1)*norm(Vector2))\n",
    "print(\"Cosine Similarity between Vector1 and Vector2:\", cosine_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxw1XSFy2V6O"
   },
   "source": [
    "### An example of appliying cosine between one vector in one hand and a list of vectors in the other hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLRhq-HYR3tD",
    "outputId": "2c3c2083-65e1-4ec5-f049-3a676acfb58b"
   },
   "outputs": [],
   "source": [
    "# define two lists or array\n",
    "Vectors = np.array([[2,1,2],[3,2,9], [-1,2,-3]])\n",
    "Vector1 = np.array([3,4,2])\n",
    "print(\"Vectors:\\n\", Vectors)\n",
    "print(\"Vectors:\\n\", Vector1)\n",
    "print()\n",
    " \n",
    "# compute cosine similarity\n",
    "cosine_value = np.dot(Vectors,Vector1)/(norm(Vectors, axis=1)*norm(Vector1))\n",
    "print(\"Cosine Similarity:\\n\", cosine_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWG8howXR-bi"
   },
   "outputs": [],
   "source": [
    "def cosine(A,B):\n",
    "    if type(B)==str :\n",
    "        B = get_vector(B)\n",
    "        return np.dot(A,B)/(norm(A, axis=1)*norm(B))\n",
    "    else :\n",
    "        return np.dot(A,B)/(norm(A, axis=1)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAlnU03I4KAy",
    "outputId": "47685c30-5346-4b11-99ea-a65f0200e659"
   },
   "outputs": [],
   "source": [
    "cosine(Vectors, Vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpH4wWGg3xS4",
    "outputId": "55508546-a720-41e6-fc2d-e4331ff8f4f3"
   },
   "outputs": [],
   "source": [
    "print(vectors.shape, vectors[:10,1], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaFHFPqF7EP_"
   },
   "outputs": [],
   "source": [
    "def get_word(vector, n=10):\n",
    "    if type(vector) == str:\n",
    "        return vector\n",
    "    else : \n",
    "        cosin = cosine(vectors, vector)\n",
    "        sorted_idx = np.argsort(-cosin)\n",
    "        return vocabulary[sorted_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PahMHH6n7KBQ"
   },
   "outputs": [],
   "source": [
    "get_word(get_vector(\"Paris\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2YTNizQNv2W"
   },
   "outputs": [],
   "source": [
    "def get_most_similar_words2(word, n=10):\n",
    "    if type(word) == str:\n",
    "        vector = get_vector(word)\n",
    "    else : \n",
    "        vector = word\n",
    "    gg = cosine(vectors, vector)\n",
    "    sorted_ids = np.argsort(-gg)\n",
    "    result = [vocabulary[i] for i in sorted_ids[:n+1] if get_word(word) not in vocabulary[i]]\n",
    "    if len(result) > n :\n",
    "        return result[:n]\n",
    "    else :\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYf5HXBG5PIa",
    "outputId": "2b263bc6-bd9f-4e3b-bc97-0cb777ed1377"
   },
   "outputs": [],
   "source": [
    "get_most_similar_words2(\"fréjus\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uOMxyQTXTLJ",
    "outputId": "9a1142b5-9ec6-4f2c-b97c-26ef1a8e3b1b"
   },
   "outputs": [],
   "source": [
    "get_most_similar_words2(\"uruguay\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIqm1BGcYmbX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W86FJ0b6XNMb"
   },
   "source": [
    "## Visualizing the vectors and their relationships: countries & capital cities\n",
    "\n",
    "Exercise:\n",
    "- Extract the set of vectors for the words given below\n",
    "- Linearly project them in 3D using the truncated singular value decomposition\n",
    "- Plot the words according to the 2nd and 3rd axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "DzRMB3sYuK3J",
    "outputId": "124f3518-2038-4af5-cb57-5d880ff7b06e"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = ['paris', 'france', 'berlin', 'allemagne', 'pékin', 'chine', 'tokyo', 'japon', 'mexico', 'mexique', 'caracas', 'venezuela']\n",
    "word_vectors = [get_vector(word) for word in words] # word vectors for the words above packed into a matrix (row-wise)\n",
    "word_vectors_2d = TruncatedSVD(n_components=3, algorithm=\"arpack\").fit_transform(word_vectors)\n",
    "plt.scatter(word_vectors_2d[:, 1], word_vectors_2d[:, 2])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, (word_vectors_2d[i, 1], word_vectors_2d[i, 2]))\n",
    "    if i % 2 == 0:\n",
    "        plt.plot(word_vectors_2d[i:i+2, 1], word_vectors_2d[i:i+2, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "TR5WgpK0JHIG",
    "outputId": "0789487c-3d16-4260-9779-23e36fe1b450"
   },
   "outputs": [],
   "source": [
    "plt.scatter(word_vectors_2d[:, 0], word_vectors_2d[:, 2])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, (word_vectors_2d[i, 0], word_vectors_2d[i, 2]))\n",
    "    if i % 2 == 0:\n",
    "        plt.plot(word_vectors_2d[i:i+2, 0], word_vectors_2d[i:i+2, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWR81DqBJSSk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aD6U1rfXdgt"
   },
   "source": [
    "## Predicting the capital city from the country\n",
    "\n",
    "Exercise :\n",
    "- Based on the previous observation, think of a way to guess the capital city given a country\n",
    "- Write a function called `find_capital` and try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld4s9xOy6p2r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We compute the average difference between vectors for countries and vectors for capital cities\n",
    "difference = np.zeros(300)\n",
    "for i in range(0, len(words), 2):\n",
    "    difference += get_vector(words[i]) - get_vector(words[i+1])\n",
    "    difference /= len(words) / 2\n",
    "\n",
    "def find_capital(country):\n",
    "    # We simply retrieve the word with the vector representation closest to the vector for the country + the mean difference calculated above\n",
    "    country_vector = get_vector(country)\n",
    "    for w in get_most_similar_words(country_vector + difference, 2):\n",
    "        if w != country:\n",
    "            return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5a8tSJIoM6nD",
    "outputId": "62542a46-294d-4fbc-a337-3598b8b900f6"
   },
   "outputs": [],
   "source": [
    "find_capital(\"canada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIJIjzyEKjRY"
   },
   "outputs": [],
   "source": [
    "differences = np.array([])\n",
    "for i in range(0, len(words), 2):\n",
    "    differences = np.append( differences, get_vector(words[i]) - get_vector(words[i+1]) )\n",
    "    difference2 = np.mean(differences)\n",
    "    difference3 = np.median(differences)\n",
    "\n",
    "def find_capital2(country):\n",
    "    country_vector = get_vector(country)\n",
    "    similar_words = get_most_similar_words2(country_vector+difference2, 10)\n",
    "    capitals = [w for w in similar_words if country not in w]\n",
    "    if len(capitals) > 3 : \n",
    "        return capitals[:3]\n",
    "    else :\n",
    "        return capitals\n",
    "\n",
    "def find_capital3(country):\n",
    "    country_vector = get_vector(country)\n",
    "    similar_words = get_most_similar_words2(country_vector + difference3, 10)\n",
    "    capitals = [w for w in similar_words if country not in w]\n",
    "    if len(capitals) > 3 : \n",
    "        return capitals[:3]\n",
    "    else :\n",
    "        return capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiANjWOT8Qoz",
    "outputId": "61a64245-b19c-4cde-be17-4b9d5de39610"
   },
   "outputs": [],
   "source": [
    "A = np.array([1,2])\n",
    "B = np.array([2,3])\n",
    "C = np.array([1,1])\n",
    "print(np.sqrt(np.sum((A-B)**2)))\n",
    "print(np.sqrt(np.sum((A-C)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vu8npqc3KJ8y",
    "outputId": "ac2f8f2e-e795-43c4-df98-44f483f1bd7f"
   },
   "outputs": [],
   "source": [
    "print(find_capital2(\"uruguay\"))\n",
    "print(find_capital2(\"canada\"))\n",
    "print(find_capital2(\"équateur\"))\n",
    "print()\n",
    "print(find_capital3(\"uruguay\"))\n",
    "print(find_capital3(\"canada\"))\n",
    "print(find_capital3(\"équateur\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tez3o_0P-9ES",
    "outputId": "d4233cba-091f-4b08-9652-92151a56a65e"
   },
   "outputs": [],
   "source": [
    "l1_diff = [] ; l2_diff = []\n",
    "for i in range(0, len(words), 2):\n",
    "    l2_diff.append(list((get_vector(words[i])-get_vector(words[i+1]))**2))\n",
    "    l1_diff.append(list(np.abs(get_vector(words[i])-get_vector(words[i+1]))))\n",
    "l2_diff = np.sqrt(np.sum(l2_diff, axis=0))\n",
    "l1_diff = np.sqrt(np.sum(l1_diff, axis=0))\n",
    "print(l2_diff.shape, l1_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY28tVZX8C-8",
    "outputId": "868cc5c2-55fe-4b31-c02a-5ea0f2328ec2"
   },
   "outputs": [],
   "source": [
    "def find_capital_l1(country):\n",
    "  country_vector = get_vector(country)\n",
    "  similar_words = get_most_similar_words2(country_vector+l1_diff, 10)\n",
    "  capitals = [w for w in similar_words if country not in w]\n",
    "  if len(capitals) > 3 : \n",
    "    return capitals[:3]\n",
    "  else :\n",
    "    return capitals\n",
    "\n",
    "print(find_capital_l1(\"uruguay\"))\n",
    "print(find_capital_l1(\"canada\"))\n",
    "print(find_capital_l1(\"équateur\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InkJCWmiA8u2",
    "outputId": "1dfcee42-4204-4cdf-f6eb-90923740f439"
   },
   "outputs": [],
   "source": [
    "def find_capital_l2(country):\n",
    "  country_vector = get_vector(country)\n",
    "  similar_words = get_most_similar_words2(country_vector+l2_diff, 10)\n",
    "  capitals = [w for w in similar_words if country not in w]\n",
    "  if len(capitals) > 5 : \n",
    "    return capitals[:5]\n",
    "  else :\n",
    "    return capitals\n",
    "\n",
    "print(find_capital_l2(\"uruguay\"))\n",
    "print(find_capital_l2(\"canada\"))\n",
    "print(find_capital_l2(\"équateur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLSEVn49XjGL"
   },
   "source": [
    "## Solving analogies\n",
    "\n",
    "We consider analogies of the following form: *A* is to *B* as *C* is to *D*. In terms of the word vectors, we should have: $u_a - u_b = u_c - u_d$\n",
    "\n",
    "Exercise:\n",
    "- Write a function that solves such an analogy in the vector space, given *A*, *B* and *C*.\n",
    "- Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1J-rnsDyCSU",
    "outputId": "bf5be34b-c0b4-4b53-ea68-1571da90a2e3"
   },
   "outputs": [],
   "source": [
    "def solve_analogy(word_a, word_b, word_c):\n",
    "    # u_d = u_c - u_a + u_b: we just have to find the word with the vector closest to the vector u_c - u_a + u_b\n",
    "    vector_d = get_vector(word_c) - get_vector(word_a) + get_vector(word_b)\n",
    "    for w in get_most_similar_words(vector_d, n=10):\n",
    "        if w not in [word_a, word_b, word_c]:\n",
    "            return w\n",
    "\n",
    "print(solve_analogy(\"homme\", \"femme\", \"roi\"))\n",
    "print(solve_analogy(\"voiture\", \"voitures\", \"camion\"))\n",
    "print(solve_analogy(\"grand\", \"haut\", \"petit\"))\n",
    "print(solve_analogy(\"ciel\", \"bleu\", \"feu\"))\n",
    "print(solve_analogy(\"chiot\", \"chien\", \"chaton\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HuVMNWuBJJ-",
    "outputId": "0aabba62-ec4a-4521-b801-75ddc3458fff"
   },
   "outputs": [],
   "source": [
    "def solve_analogy2(word_a, word_b, word_c):\n",
    "    # u_d = u_c - u_a + u_b: we just have to find the word with the vector closest to the vector u_c - u_a + u_b\n",
    "    vector_d = get_vector(word_c) - get_vector(word_a) + get_vector(word_b)\n",
    "    for w in get_most_similar_words2(vector_d, n=10):\n",
    "        if w not in [word_a, word_b, word_c]:\n",
    "            return w\n",
    "\n",
    "print(solve_analogy2(\"homme\", \"femme\", \"roi\"))\n",
    "print(solve_analogy2(\"voiture\", \"voitures\", \"camion\"))\n",
    "print(solve_analogy2(\"grand\", \"haut\", \"petit\"))\n",
    "print(solve_analogy2(\"ciel\", \"bleu\", \"feu\"))\n",
    "print(solve_analogy2(\"chiot\", \"chien\", \"chaton\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMKW1DjoBOcZ",
    "outputId": "469f054d-354e-4683-99d6-8b860a31f606"
   },
   "outputs": [],
   "source": [
    "def solve_analogy2(word_a, word_b, word_c):\n",
    "    # u_d = u_c - u_a + u_b: we just have to find the word with the vector closest to the vector u_c - u_a + u_b\n",
    "    vector_d = get_vector(word_c) - get_vector(word_a) + get_vector(word_b)\n",
    "    for w in get_most_similar_words2(vector_d, n=10):\n",
    "        if w not in [word_a, word_b, word_c]:\n",
    "            return w\n",
    "\n",
    "print(solve_analogy2(\"france\", \"paris\", \"canada\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ceSB984Bepn",
    "outputId": "d1004eea-d554-4cf1-b948-df6b6f5878bc"
   },
   "outputs": [],
   "source": [
    "def solve_analogy2(word_a, word_b, word_c):\n",
    "    # u_d = u_c - u_a + u_b: we just have to find the word with the vector closest to the vector u_c - u_a + u_b\n",
    "    vector_d = get_vector(word_c) - get_vector(word_a) + get_vector(word_b)\n",
    "    for w in get_most_similar_words2(vector_d, n=10):\n",
    "        if w not in [word_a, word_b, word_c]:\n",
    "            return w\n",
    "\n",
    "print(solve_analogy2(\"espagne\", \"madrid\", \"pérou\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOF9PhQYBlwd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
